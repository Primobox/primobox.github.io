<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Primobox Tech Blog</title>
    <description>Innover, Partager, Grandir ensemble</description>
    <link>http://0.0.0.0:4000/</link>
    <atom:link href="http://0.0.0.0:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 06 Mar 2022 15:03:36 -0600</pubDate>
    <lastBuildDate>Sun, 06 Mar 2022 15:03:36 -0600</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>Les microservices, c'est pas automatique !</title>
        <description>&lt;h2 id=&quot;un-effet-de-mode&quot;&gt;Un effet de mode&lt;/h2&gt;

&lt;p&gt;Rentrons rapidement dans le vif du sujet.
J’ai moi-même participé à cette &lt;em&gt;hype&lt;/em&gt; il y a quelques années, avec très certainement un manque de recul et un engouement démesuré pour une manière de faire qui semblait nouvelle et révolutionnaire. Dans le monde du java qui est le mien, Netflix avait pavé la route en mettant à disposition tout un tas d’outils promettants monts et merveilles, et Spring Boot - déjà très à la mode aussi - rendait la chose encore plus simple.&lt;/p&gt;

&lt;p&gt;Enormément d’entreprises (et donc de développeurs) se sont engouffrés dans cette brèche, pour déchanter quelques années plus tard.&lt;/p&gt;

&lt;p&gt;Cet article expliquera, de la manière la plus factuelle possible, l’ensemble des choses qui faut comprendre sur les microservices pour pouvoir décider, en toute connaissance de cause, s’il est pertinent de s’y lancer ou non. Aujourd’hui, l’effet de mode sur ce sujet s’est bien dissipé (bien qu’encore assez présent), et même si la technologie autour de cette pratique a bien évoluée, il n’en reste pas moins que c’est un chemin complexe et souvent anti-productif.&lt;/p&gt;

&lt;p&gt;Pour les plus avertis d’entre-vous, vous trouverez très certainement des raccourcis dans mon discours, ou des choses qui ne sont pas entièrement expliquées. Cela est voulu et assumé pour que ce billet reste digeste et ne se transforme pas en livre blanc sur le sujet. Si des zones d’ombre vous intéressent particulièrement, nous pourrons faire un article dédié à leur sujet.&lt;/p&gt;

&lt;h2 id=&quot;les-principales-problématiques-des-logiciels&quot;&gt;Les principales problématiques des logiciels&lt;/h2&gt;
&lt;p&gt;Ci-dessous, une présentation de 4 difficultés récurrentes dans le monde du logiciel. La liste n’est pas exhaustive, mais contient celles qui me semblent être les plus représentatives des problématiques du moment.&lt;/p&gt;

&lt;h4 id=&quot;la-complexité&quot;&gt;La complexité&lt;/h4&gt;
&lt;p&gt;Le plus gros problème que l’on rencontre est, à mon sens, la complexité. Avec la montée en puissance du hardware (un téléphone est maintenant plus puissant qu’un ordinateur d’il y a 10 ans, voire même 5 ans), le nombre de logiciels qui explose, l’impatience croissante des consommateurs (tout le monde veut tout, tout de suite), il en résulte mécaniquement que les logiciels que l’on produit doivent être de plus en plus complexes.&lt;/p&gt;

&lt;p&gt;On explique la complexité par le fait que l’on fait mieux que ses concurrents; elle justifie d’écrire plus de lignes de code; elle nous donne le sentiment d’avoir bien travaillé, et réussi à faire ce que d’autres ne sont même pas cabale de comprendre.&lt;/p&gt;

&lt;p&gt;Bref, la complexité se développe dans nos applications, et sans trop de surprise, le retour de bâton ne tarde en général jamais à arriver : temps de développement qui explose, montée en compétence compliquée des nouveaux, relecture hasardeuse et pénible de son propre code, etc.&lt;/p&gt;

&lt;p&gt;Si seulement il existait un moyen de réduire cette grande complexité en un ensemble de petits problèmes plus simple…&lt;/p&gt;

&lt;h4 id=&quot;la-performance&quot;&gt;La performance&lt;/h4&gt;
&lt;p&gt;Lorsque l’on met un application en production, et qu’elle fonctionne bien, la question de la scalabilité se pose : &lt;em&gt;comment faire pour servir plus de traffic ?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Il y a 3 réponses principales :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;la scalabilité verticale : on augmente la capacité des machines (ajout de ressources)&lt;/li&gt;
  &lt;li&gt;la scalabilité horizontale : on déploie de nouvelles instances&lt;/li&gt;
  &lt;li&gt;l’optimisation : on optimise le code, pour que l’application tourne mieux (oui, oui, c’est une vraie méthode, bien que souvent oubliée / ignorée)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;La scalabilité verticale a ses limites, car un serveur très performant coûte rapidement très cher. L’optimisation aussi a ses limites, car le temps investi devient à un moment bien supérieur au gain effectif. La scalabilité horizontale est un bon compromis, mais elle implique quand même quelques choses à ne pas négliger (discutées plus tard dans la suite de ce billet).&lt;/p&gt;

&lt;p&gt;Un autre aspect de la performance qu’il ne faut pas oublier, c’est les environnement de dev (donc des développeurs). Travailler sur une application trop grosse peut devenir compliqué pour le quotidien d’un dev, qui verra sa machine régulièrement à court de ressources. Tout le monde ne peut pas se payer tous les 2 ans des machines à plus de 2 000 euros, sous prétexte que &lt;em&gt;ça rame&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Existe-t-il un moyen de découper une application en plusieurs petites qui consommeraient moins ?&lt;/p&gt;

&lt;h4 id=&quot;le-modèle-de-données&quot;&gt;Le modèle de données&lt;/h4&gt;
&lt;p&gt;Vous le savez bien, quand on commence à travailler sur un logiciel, on choisi en premier… la base de données (ok, il y a de l’ironie dans cette phrase, mais elle est malheureusement très proche de la réalité). Et cette base de données devient le coeur névralgique de l’application. Elle grossi de plus en plus, on y ajoute des tables/documents/clés et des colonnes/propriétés/valeurs, et bien sûr tout le monde vient chercher dedans les informations qui l’intéresse.&lt;/p&gt;

&lt;p&gt;On se retrouve rapidement avec un système qui a grossi, et on ne sait même plus qui a besoin de quoi. Cela se traduit le plus souvent par une peur voire une incapacité à faire évoluer le modèle, et à le nettoyer (on ne veut pas casser une requête qui &lt;strong&gt;&lt;em&gt;pourrait&lt;/em&gt;&lt;/strong&gt; exister sur cette donnée). Au final, un modèle de données qui se dégrade de plus en plus (on ajoute, on ne supprime pas), et un couplage de plus en plus fort et de moins en moins maitrisé.&lt;/p&gt;

&lt;p&gt;Comment faire pour rester maître de ses données ?&lt;/p&gt;

&lt;h4 id=&quot;les-technologies&quot;&gt;Les technologies&lt;/h4&gt;
&lt;p&gt;La technologie évolue vite, plus vite que nos logiciels. Alors à un moment, il faut se lancer, et faire des mises à jours. Quand je dis “à un moment”, ce n’est pas forcément dans la minute, dans l’année, ou même dans les 5 ans. Tout cela est une gestion du risque, mais c’est un autre sujet. Par contre, c’est sûr qu’à un moment il faudra évoluer.&lt;/p&gt;

&lt;p&gt;Le problème, c’est qu’en général, il faut faire évoluer toute sa base de code en même temps car… c’est le même logiciel. Et ça…. ça pique un peu, voire beaucoup.&lt;/p&gt;

&lt;p&gt;Pire, si au lieu de faire une “simple” montée de version, on décide de changer complètement de langage ou de paradigme ? Là c’est la cata. Des semaines, mois, années de boulot pour tout ré-écrire, tout en maintenant l’ancien logiciel en parallèle (car oui, il rapporte quand même des sous en attendant). Et la cerise sur le gâteau, c’est quand le nouveau logiciel met tellement de temps à sortir, qu’il faut continuer à faire évoluer l’ancien pendant ce temps. Si vous avez quelques années d’expérience et vu 2 ou 3 sociétés différentes, il y a de grandes chances que cela vous parle, tellement c’est fréquent.&lt;/p&gt;

&lt;p&gt;Et si l’on ne migre pas ? Alors on choisi souvent entre subir des failles de sécurité, des difficultés à recruter, ou un manque de documentation sur le net.&lt;/p&gt;

&lt;p&gt;Alors, comment ne pas subir la techno, et rester en capacité d’en changer lorsque c’est nécessaire ?&lt;/p&gt;

&lt;h2 id=&quot;les-microservices-à-la-rescousse-&quot;&gt;Les microservices à la rescousse !&lt;/h2&gt;

&lt;p&gt;“Le code est pourri, on y comprend rien !”, faisons des microservices !&lt;/p&gt;

&lt;p&gt;“Mon appli consomme 8Go de ram, je ne peux pas la scaler”, faisons des microservices !&lt;/p&gt;

&lt;p&gt;“J’en ai marre que les gens tapent directement dans nos bases. On va leur faire une API”, faisons des microservices !&lt;/p&gt;

&lt;p&gt;“C’est chiant de ne pas pouvoir faire de Kotlin”, faisons des microservices !&lt;/p&gt;

&lt;p&gt;Donc si l’on veut :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;réduire la complexité en plusieurs petits problèmes plus simples,&lt;/li&gt;
  &lt;li&gt;avoir des applications qui consomment moins et qui nous permettent de scaler uniquement le nécessaire&lt;/li&gt;
  &lt;li&gt;rester maître de ses données&lt;/li&gt;
  &lt;li&gt;pouvoir faire évoluer simplement les technologies utilisées
alors les microservices semblent être le Graal.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Et sur le papier, c’est très beau ! Un ensemble de services autonomes qui discutent sagement entre eux, qui préviennent rapidement en cas de problème, qui ne font pas écrouler tout le système lors d’un bug, qui ne consomment que le strict nécessaire, qui sont gérés par des équipes différentes (mais qui discutent bien entre-elles), etc. La liste des bienfaits [marketing ?] des microservices est longue.&lt;/p&gt;

&lt;h2 id=&quot;le-revers-de-la-médaille&quot;&gt;Le revers de la médaille&lt;/h2&gt;
&lt;p&gt;Vous vous en doutez (et le ton ironique que j’emploies sciemment est un indice), ce n’est pas non plus le monde des Bisounours. Si l’on regarde de plus près, pour que cela fonctionne, il y a beaucoup de choses à prendre en compte.&lt;/p&gt;

&lt;h4 id=&quot;le-découpage-en-microservices&quot;&gt;Le découpage en microservices&lt;/h4&gt;
&lt;p&gt;Surement le sujet le plus complexe, et là où la majorité des équipes se plantent. Comment découper un affreux monolithe en jolis microservices ?&lt;/p&gt;

&lt;h6 id=&quot;la-phase-de-découpage&quot;&gt;La phase de découpage&lt;/h6&gt;
&lt;p&gt;Toute bonne migration commence par de la réflexion. La question &lt;strong&gt;&lt;em&gt;primordiale&lt;/em&gt;&lt;/strong&gt; à se poser est la suivante : comment et quoi découper ?&lt;/p&gt;

&lt;p&gt;C’est cette question qui est la plus complexe à ce stade. Un découpage trop fin augmentera le nombre de microservices nécessaires, et donc toute la complexité associée. Un découpage trop approximatif va entraîner une dépendance forte (couplage) entre les microservices, annihilant leurs effets bénéfiques. Il existe des techniques pour faire un bon découpage, et si vous ne les connaissez pas, alors c’est déjà une première alerte rouge que les microservices ne sont pas la bonne solution.&lt;/p&gt;

&lt;h6 id=&quot;la-phase-de-transition&quot;&gt;La phase de transition&lt;/h6&gt;
&lt;p&gt;Dans un monolithe, les appels de code se font de manière local (i.e. dans le même process). Par exemple, pour les langages à base de machine virtuelle, les appels entre les méthodes se font dans la même instance de VM. Hors si l’on veut découper cela en plusieurs applications, il faut changer cela, et passer par un autre protocole. En général, on favorise les APIs Web (JSON par exemple), ou les files de messages.&lt;/p&gt;

&lt;p&gt;Il y a donc une première phase de modification de l’existant, pour transformer bon nombre d’appels ad-hoc en un échange de données entre 2 parties. Au mieux l’infrastructure permettant cela est déjà en place, au pire il faut ajouter de nouveaux composants dans le système (le messaging par exemple).&lt;/p&gt;

&lt;h6 id=&quot;la-phase-de-migration&quot;&gt;La phase de migration&lt;/h6&gt;
&lt;p&gt;Une fois le périmètre des services défini, et le découplage du code effectué, on peut migrer une partie du code dans un service externe et autonome : un microservice. Les premiers sont en général simples à faire, et c’est là que la chose est insidieuse : ce n’est qu’une fois bien avancé, que l’on se rend compte des erreurs faites sur la route, et le coût de rectification est en général élevé.&lt;/p&gt;

&lt;p&gt;Les principales choses auxquelles penser sont décrites ci-dessous.&lt;/p&gt;

&lt;h4 id=&quot;lisolation-des-données&quot;&gt;L’isolation des données&lt;/h4&gt;
&lt;p&gt;Le premier problème que l’on rencontre est en général l’isolation des données. Pour que le service soit autonome, il faut qu’il soit seul maitre des ses données. Cela implique que d’autres parties de l’application ne doivent pas pouvoir lire ou modifier ses données, mais aussi bien entendu des systèmes externes (une requête manuelle ou automatique faite par une personne extérieure à l’équipe est considérée comme un système externe).&lt;/p&gt;

&lt;p&gt;Si ce n’est pas le cas, alors comment être sûr que la modification d’un format de données ne va pas avoir un impact latent sur un autre système ? Il faut donc exposer la donnée autrement (là encore, en général via le protocole HTTP ou le messaging), et définir un contrat entre notre service et l’extérieur. Notre modèle de données peut alors évoluer à sa guise, en fonction des besoins, tant que le contrat défini n’est pas rompu.&lt;/p&gt;

&lt;p&gt;C’est à ce niveau qu’est le second challenge : au lieu d’avoir un couplage local (en général validé par le compilateur), on se retrouve à devoir maintenir des contrats avec l’extérieur, donc à devoir les valider et les tester en permanence. Cela se fait via des outils à mettre en place, et des tests supplémentaires à écrire.&lt;/p&gt;

&lt;h4 id=&quot;le-déploiement-des-microservices&quot;&gt;Le déploiement des microservices&lt;/h4&gt;
&lt;p&gt;Lorsque l’on a 1 ou 2 ou 5 microservices, rien de très compliqué pour les déployer. En plus, si le travail est bien fait, ils sont indépendants, et donc ne nécessitent pas une orchestration de la mise en production (synchronisation entre plusieurs MEP pour ne rien casser).&lt;/p&gt;

&lt;p&gt;Cependant, au bout d’un moment, leur nombre augmente, et mécaniquement plusieurs autres choses aussi :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;le temps de build global (checkout, compiliation, tests divers, packaging, déploiement)&lt;/li&gt;
  &lt;li&gt;les resources utilisées (dans la majorité des techno, chaque microservice a un coût d’entrée en termes de ressources)&lt;/li&gt;
  &lt;li&gt;le nombre de personnes nécessaire pour les opérer&lt;/li&gt;
  &lt;li&gt;la latence (voir ci-dessous)&lt;/li&gt;
  &lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;L’adage “diviser pour mieux régner” implique ici de déplacer un problème de couplage de code (problème de dev) sur une problématique d’ops (le déploiement). Et donc, partir dans du microservice dans une culture ops un minimum solide est en général un suicide à petit feu. Et je ne parle même pas ici du monitoring de tous ces services, ou du debug dans un environnement distribué…&lt;/p&gt;

&lt;h4 id=&quot;la-latence&quot;&gt;La latence&lt;/h4&gt;
&lt;p&gt;Mettons tout de suite de côté le contre-argument que les systèmes peuvent être orientés événements (event-driven) ou bien asynchrones (oui, c’est bien 2 choses différentes). C’est vrai, et dans ce cas la latence est un problème bien moindre. Mais ce n’est pas encore comme cela que la majorité des systèmes sont faits. La majorité des systèmes sont majoritairement fondamentalement synchrones, et vont voir leur latence exploser lors d’un passage sur une architecture microservice.&lt;/p&gt;

&lt;p&gt;C’est assez simple à s’en rendre compte (quoi qu’il faut y penser !) : si au lieu de faire des appels au sain d’une même application (donc latence très faible, de l’ordre de la nano-seconde), vous le faites via un protocole comme HTTP (même avec des optimisations comme du protobuf ou parquet), on passe rapidement sur un ordre de grandeur de la milliseconde… au mieux. Rajoutez une couche de SSL entre vos services, et c’est encore une poignée de millisecondes de perdus à chaque appel. Ajoutez de l’authentification (déchiffrage de token par exemple), et rebelote.&lt;/p&gt;

&lt;p&gt;Alors oui, on peut mettre en place une architecture pour éviter ces 2 choses là, mais on le fait généralement une fois que l’on a eu ces problèmes, et surtout si, encore une fois, on a une maturité d’ops suffisante pour gérer cela. Une nouvelle fois, soit la latence augmente, soit on déporte le problème sur les ops, là où n’y en avait pas avant.&lt;/p&gt;

&lt;h4 id=&quot;le-monitoring&quot;&gt;Le monitoring&lt;/h4&gt;
&lt;p&gt;Dans tout système, on doit pouvoir savoir ce qu’il s’est passé quand quelque chose ne va pas. C’est à cela que sert la majorité du monitoring. “Suivre les chiffres” permet surtout de s’assurer que tout va bien.&lt;/p&gt;

&lt;p&gt;Monitorer correctement une application n’est pas si simple. Alors en monitorer 10, 20, 50… Il ne s’agit ici plus de monitorer uniquement ses microservice, mais de monitorer les interactions entre tous les microservices : savoir qui discute avec qui, comment, pourquoi. Et si quelque chose ne tourne pas rond, remonter le fil de service en service jusqu’à trouver le coupable. Et ça… c’est compliqué dans un monde distribué. Plus de stacktrace pour vous montrer par quelles méthodes le code est passé. Il faut retrouver les appels HTTP avec leur payload, ou les messages échangés.&lt;/p&gt;

&lt;p&gt;Bien entendu, il existe là encore des outils pour faire cela. Par exemple, &lt;a href=&quot;https://opentracing.io&quot; target=&quot;_blank&quot;&gt;OpenTracing&lt;/a&gt;. Et c’est encore une fois quelque chose que nous n’avions pas besoin de faire avant, donc du temps, de l’énergie, de la maintenance en plus.&lt;/p&gt;

&lt;h4 id=&quot;la-jungle-des-technos&quot;&gt;La jungle des technos&lt;/h4&gt;
&lt;p&gt;Pour terminer cette partie, il faut parler de la technologie. Comme évoqué au début de ce post, la technologie va vite, et les besoins et la hype autour de certains choses sont inéluctables. La question n’est pas de savoir &lt;em&gt;si&lt;/em&gt; on va devoir évoluer, mais &lt;em&gt;quand&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Les microservices, en isolant les bases de code de chaque service, rendent très simple de développer chaque service dans une technologie différente. Il est vrai que lorsque l’on veut faire quelque chose de nouveau, il faut se demander &lt;em&gt;quelle techno&lt;/em&gt;, &lt;em&gt;quel paradigme&lt;/em&gt; sont le plus adaptés au besoin.&lt;/p&gt;

&lt;p&gt;Mais bien souvent on dérape vite, et les microservices se transforment en un gigantesque bac à sable de test de techno. &lt;em&gt;“C’est juste un microservice parmi d’autre, au pire si ça ne fonctionne pas on le refait !”&lt;/em&gt;. Bah… non.&lt;/p&gt;

&lt;p&gt;Avoir un ensemble hétérogène de technologies et de pratiques dans une entreprise rend compliqué l’apprentissage et la mobilité interne. Je ne dis pas qu’il faut l’éviter à tout prix. Je dis simplement qu’en général cela se fait sans vraiment de contrôle ou de stratégie, et les microservices réduisent encore un peu plus les garde-fous sur ces sujets, car les échanges entre service se font sur la base de contrats, indépendamment de la techno utilisée.&lt;/p&gt;

&lt;p&gt;Et contrairement à ce que l’on pense, refaire un microservice (qui n’est pas forcément un nanoservice) dans une autre techno, n’est pas forcément trivial.&lt;/p&gt;

&lt;h2 id=&quot;est-ce-que-les-microservices-sont-un-anti-pattern-darchitecture&quot;&gt;Est-ce que les microservices sont un anti-pattern d’architecture&lt;/h2&gt;
&lt;p&gt;Ou dit autrement, &lt;em&gt;faut-il les éviter&lt;/em&gt; ?&lt;/p&gt;

&lt;p&gt;La réponse est claire : &lt;strong&gt;&lt;em&gt;Non&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;L’architecture microservice n’est pas un mauvais choix d’architecture en tant que tel. Le mauvais choix serait de s’y lancer sans bien en comprendre les tenants et aboutissants. Elle règle un certain nombre de problèmes, mais en crée d’autres. Comme très souvent en informatique, il s’agit d’un choix à faire (trade-off en anglais).&lt;/p&gt;

&lt;p&gt;Le ton ironique utilisé à de multiples reprises vise à mettre l’accent sur des choses que l’on pense naïvement bonnes au premiers abords (et j’ai commencé par avouer y être moi-même tombé il y a quelques années), mais qui ont des conséquences importantes. J’espère au moins que cela vous fera réfléchir avant de vous y lancer.&lt;/p&gt;

&lt;p&gt;Alors, quand faire du microservice ? Déjà, ce n’est pas forcément un choix binaire. Ce n’est pas soit &lt;em&gt;TOUT&lt;/em&gt; en microservice, soit &lt;em&gt;RIEN&lt;/em&gt;. On peut très bien faire 2 ou 3 microservices qui cohabitent avec un monolithe (mais un monolithe bien foutu !). Si l’on a besoin de scaler une petite partie de l’application, d’utiliser une techno particulière pour des raisons techniques, juridique, business, etc., ou bien de séparer la base de code du reste pour une bonne raison, alors l’architecture microservice est &lt;em&gt;peut-être&lt;/em&gt; adaptée.&lt;/p&gt;

&lt;p&gt;Dans ce cas, il reste à se poser la question suivante : &lt;em&gt;Est-ce que les bénéfices seront supérieurs au coût investi ?&lt;/em&gt;. Nous avons vu plus haut que pour fonctionner correctement, un architecture microservice à besoin de plusieurs choses :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;un découpage correct (= du temps)&lt;/li&gt;
  &lt;li&gt;une isolation des données (= de l’expertise dev)&lt;/li&gt;
  &lt;li&gt;un déploiement rôdé (= de l’expertise ops)&lt;/li&gt;
  &lt;li&gt;de monitoring (= de l’expertise ops)&lt;/li&gt;
  &lt;li&gt;d’infrastructure (load balancing, messaging, tracing, resillience, orchestrateur, etc.)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Alors oui, si votre maturité sur ces sujets est assez élevée, vous en tirerez surement des bénéfices. Si non, ce n’est pas grave, il y a d’autres solutions.&lt;/p&gt;

&lt;h2 id=&quot;une-autre-solution-&quot;&gt;Une autre solution ?&lt;/h2&gt;
&lt;p&gt;Si vous pensiez échapper au fameux terme de &lt;strong&gt;&lt;em&gt;DDD&lt;/em&gt;&lt;/strong&gt; (&lt;em&gt;Domain Driven Design&lt;/em&gt;), alors vous avez eu tord :)&lt;/p&gt;

&lt;p&gt;Au début de l’article, j’indique que la complexité est selon moi le plus gros problème des applications. Les autres problèmes ajoutent de l’huile sur le feu, mais ne me semble pas aussi handicapant. Beaucoup d’équipe se sont tournées vers les microservices en pensant réduire leur complexité métier en découpant leur logique en plusieurs services. L’idée est bonne, mais il y a 2 choses à ne pas oublier : savoir découper correctement, et accepter une augmentation de la complexité d’infrastructure en échange. Et c’est là que beaucoup d’entreprise déchantent, car elles n’avaient pas prévu ce palier.&lt;/p&gt;

&lt;p&gt;Une autre solution est donc… de rester sur un monolithe. Oui, en 2022, on peut encore faire des monolithes ! Mais pas n’importe comment. Un monolithe bien pensé, sans toute la complexité d’infrastructure qu’amènent les microservices. Et pour cela, quoi de mieux que d’utiliser le &lt;strong&gt;&lt;em&gt;DDD&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Car oui, on en revient toujours à ça. La complexité. Comment la réduire ? Bien comprendre son domaine, et créer des sous-domaines adaptés. L’important n’est pas comment ils communiquent (par API Web, messages, RPC, etc.), mais bien de comment ils sont découpés. On peut donc pa,rfaitement les mettre dans un monolithe, et il sera toujours temps de créer des microservices le moment venu, où non seulement nous serons prêt à traiter la complexité qu’ils apportent, mais aussi et surtout lorsque nous aurons de vrais problèmes que les microservices peut adresser.&lt;/p&gt;

&lt;p&gt;En gros, quand vous vous lancer dans un nouveau projet, ne partez pas en microservices par défaut sous prétexte qu’&lt;em&gt;“on est en 2022 quand même !”&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Pour finir cet article qui était plus long que prévu (et qui pourrait l’être bien plus), retenez une chose : les microservices coûtent cher, en terme de temps, d’argent, et de personnes. Ce n’est pas un choix idiot, mais ça ne doit pas être un choix par défaut ou par ignorance. Ok, c’est à la mode. Et alors ?!&lt;/p&gt;

&lt;p&gt;Si vous voulez faire des microservices, commencez par bien comprendre et maitriser le &lt;strong&gt;&lt;em&gt;DDD&lt;/em&gt;&lt;/strong&gt;. On ne peut pas faire de microservices correctement sans avoir une vision claire des frontières entre les services. C’est une tâche complexe qui nécessite de l’expertise.&lt;/p&gt;

&lt;p&gt;Par contre, on peut faire du &lt;strong&gt;&lt;em&gt;DDD&lt;/em&gt;&lt;/strong&gt; sans forcément faire de microservices. Et il ne faut pas en avoir honte.&lt;/p&gt;

&lt;p&gt;A bon entendeur…&lt;/p&gt;

</description>
        <pubDate>Sun, 06 Mar 2022 00:00:00 -0600</pubDate>
        <link>http://0.0.0.0:4000/les-microservices-cest-pas-automatique/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/les-microservices-cest-pas-automatique/</guid>
        
        
        <category>TDD</category>
        
        <category>Architecture</category>
        
        <category>Microservices</category>
        
      </item>
    
      <item>
        <title>Le “Messager” : un projet pas comme les autres chez Primobox</title>
        <description>&lt;p&gt;Trouver une entreprise dans laquelle on peut progresser, apprendre, innover, tout en forgeant un logiciel de qualité et des compétences partageables à tout le monde, n’est pas chose courante.&lt;/p&gt;

&lt;p&gt;Primobox est de cette trempe là.&lt;/p&gt;

&lt;p&gt;Laissez-moi vous raconter brièvement cette aventure que j’ai eu la chance de vivre.&lt;/p&gt;

&lt;h2 id=&quot;genèse&quot;&gt;Genèse&lt;/h2&gt;

&lt;p&gt;Vous connaissez l’adage “Diviser pour mieux régner” ? C’est ce que nous invite à faire l’approche DDD (Domain Driven Design). Et c’est avec ce principe en tête (délimiter des Contextes Explicites et &lt;a href=&quot;https://fr.wikipedia.org/wiki/Topologie_discr%C3%A8te&quot;&gt;Discrets&lt;/a&gt; &lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;) qu’un projet de Messager autonome est né chez Primobox (pour faire simple, le Messager est celui chargé de remettre le courrier à ses destinataires).&lt;/p&gt;

&lt;p&gt;Doté d’une grande responsabilité, simple au premier abord mais qui permet d’envisager des options et des possibilités multiples, en toute autonomie.&lt;/p&gt;

&lt;p&gt;Une fois ce domaine (contexte) métier spécifique identifié , parmi les autres besoins clients que doivent satisfaire les solutions proposées par Primobox, il était plus facile de lancer un chantier ciblé de modernisation du code.&lt;/p&gt;

&lt;p&gt;Avec un périmètre et des relations bien définis, ce véritable “métier dans le métier” allait pouvoir prendre son envol.&lt;/p&gt;

&lt;h2 id=&quot;vision&quot;&gt;Vision&lt;/h2&gt;

&lt;p&gt;Un projet réussi commence par une vision. &lt;a href=&quot;https://www.linkedin.com/in/alexandre-fillatre-696643168/&quot;&gt;Alexandre Fillatre&lt;/a&gt;, CTO chez Primobox a su initier et nourrir cette vision. Basée sur une idée simple : les différentes phases qui composent l’activité de l’offre de service chez Primobox (dématérialisation de la relation entre employés et employeurs) ont chacune une raison d’exister propre, tout en étant capable d’interagir avec les autres parties et d’évoluer de manière autonome. Alexandre nous a partagé cette vision et nous a fait confiance pour la mettre en œuvre.&lt;/p&gt;

&lt;h2 id=&quot;utilisateurs&quot;&gt;Utilisateurs&lt;/h2&gt;

&lt;p&gt;En amont, un vrai travail pour comprendre le besoin utilisateur avait été initié et je l’ai traduit en éléments que nous allions mettre dans le cœur du “Messager”.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://stephaniewalter.design/fr/blog/introduction-aux-user-journey-maps-modeles-pdf-a-telecharger/&quot;&gt;L’atelier de Wording et les User Journeys&lt;/a&gt; m’ont été très utiles pour cerner le domaine métier dans son ensemble et dans ses particularités.&lt;/p&gt;

&lt;h2 id=&quot;clarté&quot;&gt;Clarté&lt;/h2&gt;

&lt;p&gt;La clarté se gagne par l’analyse. Grâce aux travaux préliminaires de l’équipe Produit et Ergonomie, j’ai pu coucher sur le papier une carte (à la Wardley) des interactions entre le Messager et les autres éléments qui constituent la solution globale dont nos clients ont besoin.&lt;/p&gt;

&lt;p&gt;Cela permet de savoir quelles fonctionnalités sont plus importantes, lesquelles sont annexes, lesquelles sont laissées à la responsabilité d’autres modules (existants ou à créer) voire externalisées.&lt;/p&gt;

&lt;p&gt;Des choix stratégiques importants sur le périmètre fonctionnel ont été faits afin de réduire la charge de travail et la complexité présente sur certains produits.&lt;/p&gt;

&lt;p&gt;Cela dessine une forme d’architecture, plus basée sur les besoins que la technique.&lt;/p&gt;

&lt;p&gt;Cela nous libère aussi des détails techniques, car sur un &lt;a href=&quot;https://github.com/ddd-crew/context-mapping&quot;&gt;Context Mapping&lt;/a&gt; (toujours cette notion de cartographie) se dessinent les frontières entre les &lt;a href=&quot;https://martinfowler.com/bliki/BoundedContext.html&quot;&gt;Bounded Contexts&lt;/a&gt;; et l’on voit facilement les choix contraints par l’existant (legacy), et par ailleurs les espaces où les contraintes changent de nature. Par exemple, là où la performance est plus importante que la compatibilité.&lt;/p&gt;

&lt;h2 id=&quot;audace&quot;&gt;Audace&lt;/h2&gt;

&lt;p&gt;Prendre des paris audacieux, après tout, pourquoi pas ? Pourquoi rester conforme à ce qui a été fait par le passé et se priver de progresser ?&lt;/p&gt;

&lt;p&gt;Parlons du langage de développement. Primobox a un historique Java solidement ancré.&lt;/p&gt;

&lt;p&gt;Moi j’arrivais du monde .Net.&lt;/p&gt;

&lt;p&gt;Alexandre Fillatre a su discerner qu’un bon développeur ne saurait s’arrêter à une syntaxe donnée, l’essentiel étant ce que l’on sait obtenir de tel ou tel langage de développement.&lt;/p&gt;

&lt;p&gt;La POO est une chose universelle mais les langages modernes évoluent pour être plus hydrides et flirtent plus facilement avec la Programmation Fonctionnelle. C’est le cas de C#, puis de Java qui lui a emboîté le pas.&lt;/p&gt;

&lt;p&gt;Quitte à s’éloigner de C# 9 pour aborder la JVM, autant opter pour un langage du même niveau.&lt;/p&gt;

&lt;p&gt;C’est là que nous avons pensé à … Kotlin !&lt;/p&gt;

&lt;p&gt;Etant pour ma part un adepte précoce de C# et de l’écosystème .Net, je n’avais jamais eu à me frotter au monde Java ailleurs que dans mes études. Grâce à Kotlin, franchir le cap a été pour moi d’une facilité déconcertante.&lt;/p&gt;

&lt;p&gt;J’ai retrouvé tous mes réflexes acquis en C# avec une syntaxe encore plus élégante. Ayant l’habitude de Linq, Kotlin est naturellement provisionné pour faire la même chose. En mieux ! Et il est facile de trouver de &lt;a href=&quot;https://kotlinlang.org/docs/collection-operations.html#common-operations&quot;&gt;l’aide&lt;/a&gt; et des &lt;a href=&quot;https://github.com/mythz/kotlin-linq-examples&quot;&gt;exemples&lt;/a&gt;. Et des très bons &lt;a href=&quot;https://www.baeldung.com/kotlin/&quot;&gt;tutos&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;arrière-boutique&quot;&gt;Arrière boutique&lt;/h2&gt;

&lt;p&gt;Ah oui, si vous cherchez des ressources sur Kotlin dans les Internets, vous verrez que ce langage est la panacée pour les applications mobiles. Et pourtant ! C’est excessivement réducteur.&lt;/p&gt;

&lt;p&gt;Kotlin produit (aussi) du bytecode qui va tourner sur la JVM. Donc c’est un parfait candidat pour tout le code backend. C’est ce que nous avons fait pour cette application complexe, avec une architecture très évoluée, ce qui nous a permis d’être parfaitement intégré dans l’existant Java et surtout très performant.&lt;/p&gt;

&lt;h2 id=&quot;idiomes&quot;&gt;Idiomes&lt;/h2&gt;

&lt;p&gt;Quitte à choisir un langage qui nous était inconnu (à moi et mon coreligionnaire, pur Javaiste pour sa part) jusqu’ici, &lt;a href=&quot;https://kotlinlang.org/docs/idioms.html&quot;&gt;autant le faire bien et complètement&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Kotlin a de multiples talents. Facile d’apprentissage, il emprunte un peu à Typescript, C#, Scala et bien sûr Java, puisqu’il produit du bytecode ciblé pour la JVM.&lt;/p&gt;

&lt;p&gt;Son éditeur (Jetbrains) a tout fait pour que les développeurs Java s’y retrouvent, et puissent même ré-utiliser n’importe quelle classe du JDK ou n’importe quelle lib Java. Et ça fonctionne très bien. On peut même écrire du code “façon Java” (utiliser des exceptions, mettre des if en pagaille, des null partout…).
Bref, si on n’y prenait garde, on écrirait presque du Kotlin qui ressemble à du “mauvais” Java (je veux dire par là du Java d’avant guerre, avant la version 8 si vous préférez…).&lt;/p&gt;

&lt;p&gt;Pourtant avec Kotlin, tout est fait pour écrire du code “élégant”. J’en veux pour preuve la non nullabilité des types par défaut, &lt;a href=&quot;https://medium.com/@johnmcclean/dysfunctional-programming-in-java-2-immutability-a2cff487c224&quot;&gt;l’immutabilité&lt;/a&gt; par défaut, la présence des data classes (équivalent des Records de C# ou Java 16) parmi tant de choses qui m’ont enchantées.
On notera aussi que Kotlin dispose nativement de structures de données avancées (Pair, Triple, Linked List, Tree, etc…) et de possibilités de &lt;a href=&quot;https://www.baeldung.com/kotlin/category/functions&quot;&gt;manipulation de fonctions&lt;/a&gt; qui sont juste délicieuses.&lt;/p&gt;

&lt;p&gt;Et j’allais oublier de mentionner les très &lt;a href=&quot;https://www.baeldung.com/kotlin/coroutines&quot;&gt;puissantes co-routines&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;attention&quot;&gt;Attention&lt;/h2&gt;

&lt;p&gt;Tout au long de notre travail, une attention particulière a été portée aux autres membres de l’équipe. Nous avons communiqué régulièrement :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;sur l’avancée du projet, même si nous n’avions pas de revue de sprint (on en parle plus loin), sur les innovations ou techniques que nous avions choisi de mettre en œuvre, car celles-ci pouvaient aussi trouver leur place dans d’autres projets du groupe.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nous sommes aussi dans une démarche d’invitation permanente : tous les autres membres de la R&amp;amp;D peuvent venir collaborer au projet, apprendre Kotlin ou tout autre concept que nous avons mis en œuvre.&lt;/p&gt;

&lt;h2 id=&quot;langage-naturel&quot;&gt;Langage Naturel&lt;/h2&gt;

&lt;p&gt;Le langage des utilisateurs et des experts métier a été le nôtre tout le long de la réalisation.&lt;/p&gt;

&lt;p&gt;Pas de jargon de développeurs.&lt;/p&gt;

&lt;p&gt;Notre domaine métier est en français. Toute la modélisation et le codage du logiciel se sont donc faits dans cette belle langue.&lt;/p&gt;

&lt;p&gt;Nous avons réservé l’anglais pour les parties purement techniques (logées dans des composants isolés et accessibles via les Ports &amp;amp; Adaptateurs, conformément à l’architecture hexagonale exposée plus loin); par exemple la mécanique d’accès à la base de données ou au bus de message.&lt;/p&gt;

&lt;p&gt;C’est très pratique pour se rendre compte au premier coup d’œil si notre métier (en français) reste pur et ne se mélange pas avec des considérations techniques (en anglais).&lt;/p&gt;

&lt;h2 id=&quot;stratégie&quot;&gt;Stratégie&lt;/h2&gt;

&lt;p&gt;L’approche DDD est un guide dans la nuit. Ce n’est pas à proprement parler une méthode, et surtout pas un framework. C’est un ensemble d’outils et de bonnes pratiques, tout à fait compatible avec l’agilité et le software craftsmanship.&lt;/p&gt;

&lt;p&gt;Nous avons eu cette approche d’emblée, dès les premières heures du projet. C’est, il me semble, la condition sine qua non pour réussir.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/uploads/articles/8o9r2etj2tth05ulw2f9.jpeg&quot; alt=&quot;DDD starter&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Comme dit précédemment, j’ai commencé par la mise en place d’une Wardley Map, puis avec &lt;a href=&quot;https://www.linkedin.com/in/damien-boue/&quot;&gt;Damien Boué&lt;/a&gt; nous avons travaillé sur des Bounded Contexts Maps. Cela nous a permis de nous synchroniser aussi avec les équipes Produit.&lt;/p&gt;

&lt;h2 id=&quot;tactique&quot;&gt;Tactique&lt;/h2&gt;

&lt;p&gt;En DDD la stratégie s’accompagne toujours d’une tactique, je ne vais pas vous faire ici un cours de DDD, les ressources sur Internet ne manquent pas.&lt;/p&gt;

&lt;p&gt;Je ne vais pas vous parler ici des essentielles décompositions en agrégats, entités et value objects (chasser la Primitive Obsession).&lt;/p&gt;

&lt;p&gt;Je vous dirai seulement qu’une des leçons que nous avons apprises est de songer sérieusement à limiter la taille de nos agrégats ! (cf ces &lt;a href=&quot;https://www.dddcommunity.org/library/vernon_2011/&quot;&gt;bons conseils peu connus de Vaughn Vernon&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;Jusqu’à ce qu’ils ne contiennent qu’une entité. Cette idée peut vous paraître saugrenue mais vous lui direz merci quand vous verrez la complexité accidentelle poindre son nez.&lt;/p&gt;

&lt;p&gt;Bien sûr cela demande à réfléchir plus et surtout à ne pas se laisser entraîner par une conception basée sur le Mapping Objet Relationnel (ORM ou Objet Documents Mapping dans le cas des entrepôts NoSQL) qui, entre autres inconvénients, pousse notre modèle à être anémique. Mais aussi lorsque l’exécution de nos adapters devient concurrente (comme dans toutes les API Web), nous aurait obligé à poser des verrous transactionnels (et donc faire effondrer la performance). Cela est inévitable lorsque les agrégats sont trop gros et que l’on veut y accéder en écriture.&lt;/p&gt;

&lt;p&gt;Donc, gardons les atomiques !&lt;/p&gt;

&lt;h2 id=&quot;coeur&quot;&gt;Coeur&lt;/h2&gt;

&lt;p&gt;L’une des (nombreuses) brillantes idées de ce projet a été de suivre le précepte de “&lt;a href=&quot;https://www.destroyallsoftware.com/screencasts/catalog/functional-core-imperative-shell&quot;&gt;Functional Core/ Imperative Shell&lt;/a&gt;”, introduit en 2012 dans la communauté Ruby, puis repris plus récemment par &lt;a href=&quot;https://www.kennethlange.com/&quot;&gt;Kenneth Lange&lt;/a&gt; et aussi par &lt;a href=&quot;https://www.slideshare.net/ThomasPierrain/hexagonal-architecture-vs-functional-core-iom&quot;&gt;Thoman Pierrain &amp;amp; Bruno BOUCARD&lt;/a&gt; ;&lt;/p&gt;

&lt;p&gt;Cette approche a d’énormes avantages, citons-en 2 :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;d’abord repousser les effets de bord (les fameux, ceux qui rendent vos tests trop compliqués, plus du tout isolés, voire inconsistants et cachent de nombreux bugs) en dehors des considérations métier.&lt;/li&gt;
  &lt;li&gt;corollaire : cela vous permet de vous concentrer sur la seule logique métier de manière fonctionnelle, c’est-à-dire en privilégiant &lt;a href=&quot;https://medium.com/@johnmcclean/dysfunctional-programming-in-java-2-immutability-a2cff487c224&quot;&gt;l’immutabilité&lt;/a&gt; et la &lt;a href=&quot;https://sookocheff.com/post/fp/why-functional-programming/&quot;&gt;transparence référentielle&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Cette façon de penser le logiciel en y plaçant un cœur purement fonctionnel (dans les 2 sens du terme) permet d’isoler vraiment les tests métiers et donc &lt;a href=&quot;https://www.destroyallsoftware.com/blog/2014/test-isolation-is-about-avoiding-mocks&quot;&gt;de se passer entièrement des mocks à cet endroit&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dans le cœur métier propre du Messager sont également apparues d’autres frontières, et donc d’autres Bounded Context pour des composants qui avaient besoin de pouvoir évoluer sans casser les autres. Tout ce travail d’&lt;em&gt;isolation&lt;/em&gt; (via des ACL, anti corruption layers) est primordial pour ne pas s’enfermer dans une complexité accidentelle et dans ce qui devient inexorablement, malgré toute bonne volonté, une “big ball of mud” (grosse boule de boue).&lt;/p&gt;

&lt;h2 id=&quot;hexagone&quot;&gt;Hexagone&lt;/h2&gt;

&lt;p&gt;Il y a le cœur fonctionnel, et il y a la coquille (shell en Anglais). C’est ce que l’on retrouve aussi dans les &lt;a href=&quot;https://alistair.cockburn.us/hexagonal-architecture/&quot;&gt;architectures hexagonales&lt;/a&gt; (ou &lt;a href=&quot;https://blog.cleancoder.com/uncle-bob/2012/08/13/the-clean-architecture.html&quot;&gt;Clean Architecture&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Dans la partie coquille (hors cœur métier donc) on va retrouver les ports et adaptateurs.&lt;/p&gt;

&lt;p&gt;C’est cette philosophie que nous avons appliquée fortement.&lt;/p&gt;

&lt;p&gt;Et nous avons fabriqué des adaptateurs techniques pour toute situation spécifique.&lt;/p&gt;

&lt;p&gt;L’absorption de commandes venues d’une API REST est un adaptateur indépendant. Il a une dépendance directe avec les objets métiers.
Par contre pour toute opération en base de données (nous avons, en prévision d’un CQRS séparé les opérations de lecture et celles d’écriture), il y a des adaptateurs dédiés.&lt;/p&gt;

&lt;p&gt;Il en va de même pour les opérations d’envoi et de réception de messages dans un bus (afin de prévenir les agents dans d’autres Bounded Contexts qu’un événement important s’est passé dans notre domaine.&lt;/p&gt;

&lt;h2 id=&quot;qualité&quot;&gt;Qualité&lt;/h2&gt;

&lt;p&gt;TDD offre ce double avantage d’être la méthode d’écriture du logiciel (et non de test) qui nous a permis de faire du design émergent guidé par le DDD tactique et de toujours se fixer des petits pas. Et bien sûr, on obtient une couverture de tests très satisfaisante, puisqu’aucune ligne de code ne devrait être écrite si elle n’est pas justifiée par un test.&lt;/p&gt;

&lt;p&gt;Kotlin (encore lui !) vient avec une géniale librairie : Kotest. Attention à ne pas faire comme moi au début, de faire la confusion entre KotlinTest et Kotest.&lt;/p&gt;

&lt;p&gt;C’est bien Kotest qui permet de choisir parmi moult styles de tests, il y en a vraiment pour tout le monde : style Behaviour Driven Development (celui que nous avons choisi), style Scala, Ruby, Cucumber ou JavaScript/TypeScript. Ou ce bon vieux JUnit.&lt;/p&gt;

&lt;p&gt;Écrire des tests, c’est bien joli, mais encore faut-il s’assurer qu’ils servent à quelque chose et qu’ils sont robustes.&lt;/p&gt;

&lt;p&gt;Les outils déjà en place pour les autres projets Java de l’entreprise (Jenkins, SonarQube, un scanner de vulnérabilité des dépendances) se sont parfaitement intégrés à notre nouveau projet Kotlin.&lt;/p&gt;

&lt;p&gt;La Couverture de code a pu donc être constamment mesurée, mais j’en dirai plus au prochain chapitre.&lt;/p&gt;

&lt;p&gt;D’autres outils sont venus renforcer cette recherche de qualité :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.archunit.org/getting-started&quot;&gt;ArchUnit&lt;/a&gt;, pour vérifier en permanence le bon usage des dépendances et &lt;a href=&quot;https://blog.scottlogic.com/2019/12/05/unit-test-your-architecture-with-archunit.html&quot;&gt;vérifier que nous ne cassions pas les principes de l’architecture hexagonale&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.baeldung.com/introduction-to-gatling&quot;&gt;Gatling&lt;/a&gt; pour s’assurer que notre solution tient la charge en situation réelle&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;rigueur&quot;&gt;Rigueur&lt;/h2&gt;

&lt;p&gt;Un grand enjeu de la qualité logicielle semble être la couverture de code, mais cette mesure peut s’avérer erronée, comme je le prouve dans &lt;a href=&quot;https://www.linkedin.com/posts/guillaumese_des-mutants-dans-le-code-activity-6870318621411876864-RD_g&quot;&gt;ma présentation sur les tests par mutation de code&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Dans ce projet, il nous a paru opportun de consolider notre approche TDD, parce qu’après tout nous sommes tous faillibles, et qu’un outil qui nous montre que nous manquons de tests, que des bugs sont encore présents, est tout simplement une aubaine.&lt;/p&gt;

&lt;p&gt;Nous avons choisi la lib PiTest, qui fonctionne sur le ByteCode Java, et donc très bien avec Kotlin.&lt;/p&gt;

&lt;p&gt;Simple d’usage, facile à ajouter à un pipeline d’intégration continue, cet outil va nous aider à mieux coder et mieux tester (l’un ne va pas sans l’autre). Il nous a rappelé sans faillir aux règles du TDD (ne pas écrire une instruction qui ne soit justifiée par un test).&lt;/p&gt;

&lt;p&gt;Par contre, il est avisé d’utiliser ce genre d’outil sur du nouveau code plutôt que sur du legacy, et de cibler du code purement métier, c’est-à-dire au centre (functional core) de l’architecture hexagonale.&lt;/p&gt;

&lt;h2 id=&quot;paradigme-changement-de&quot;&gt;Paradigme (changement de)&lt;/h2&gt;

&lt;p&gt;Ce n’est pas chose facile que de bousculer (un peu) les habitudes des développeurs. Alors que la programmation orientée objet est maîtrisée par tous mes collègues, je leur ai fait la proposition de parier sur l’immutabilité.&lt;/p&gt;

&lt;p&gt;L’immutabilité, c’est quoi ?  Une idée qui nous vient de la programmation fonctionnelle mais qui s’applique très bien à la POO. Le principe est simple : quand les objets ne “mutent” pas (comprendre : ne changent pas d’état) alors ils sont plus facile à maîtriser, à comprendre et surtout on évite beaucoup, beaucoup de bugs car on limite grandement les effets de bord dans les méthodes de ces objets immuables.&lt;/p&gt;

&lt;p&gt;Mieux encore, cette immutabilité est facile à obtenir avec des langages tels que Kotlin (celui que nous avons choisi pour ce projet) ou même Java (le mot clé &lt;em&gt;final&lt;/em&gt; existe et il a été ensuite complété avec des librairies qui poussent une vraie immutabilité des objets, comme par exemple  &lt;a href=&quot;https://www.baeldung.com/immutables&quot;&gt;https://www.baeldung.com/immutables&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Elle permet de transitionner naturellement vers une écriture de code plus “fonctionnelle” c’est-à-dire avec une meilleur répartition des responsabilités (voir chapitre suivant), et une plus grande intégrité référentielle.&lt;/p&gt;

&lt;h2 id=&quot;solide&quot;&gt;Solide&lt;/h2&gt;

&lt;p&gt;Notre attention s’est focalisée sur la production d’ un code SOLID. Ce n’est pas facile de vous parler des principes d’un code SOLID, surtout que cela fait partie de la grande famille du code “propre” (Clean Code). Le premier principe est peut être le plus important et le plus simple à comprendre : Simple Responsibility. Et tous les autres en découlent. Nous avons toujours cherché dans ce projet à exprimer et répartir les responsabilités de façon très claire et très cohérente entre les différents modules.&lt;/p&gt;

&lt;p&gt;Que ce soit dans le découpage métier (Bounded Contexts, DDD Stratégique) ou dans l’approche technique (Archi Héxagonale DDD Tactique), notre objectif a tout le temps été de limiter la responsabilité à un niveau minimal et acceptable, afin de mieux séparer et isoler ces responsabilités. Les cartes CRC nous ont aussi beaucoup aidé à y voir plus clair dans notre design.&lt;/p&gt;

&lt;h2 id=&quot;découplé&quot;&gt;Découplé&lt;/h2&gt;

&lt;p&gt;Le découplage est un fondamental à la fois de l’architecture d’un logiciel mais aussi de la journée ordinaire d’un développeur. Il s’agit simplement de ne pas accumuler la complexité et les interactions douteuses qui peuvent se loger dans le code. Pour cela nous avons fait le choix d’abstractions pour définir et maîtriser ces fameuses dépendances.&lt;/p&gt;

&lt;p&gt;L’idée est d’exprimer simplement les choses en termes de “quoi” et non de “comment”.&lt;/p&gt;

&lt;p&gt;Exemple : au lieu de dire à notre code “je veux une base de données Mongo pour stocker des informations”, nous avons établi une abstraction (interface) qui dit “je veux pouvoir stocker cette information”. Le “comment” ne nous intéresse absolument pas.&lt;/p&gt;

&lt;p&gt;En se référant à cette abstraction (“Je_veux_stocker_information_X”), nous voilà libres de son implémentation. Et c’est double bénéfice.&lt;/p&gt;

&lt;p&gt;D’abord nous pouvons choisir librement l’implémentation et en changer à tout moment au cours de la vie du projet (nous avons choisi Mongo DB mais peut être que ce choix sera remis en cause).&lt;/p&gt;

&lt;p&gt;Et surtout, pendant les tests fonctionnels, nous n’avons pas l’obligation de mettre en route la fameuse base de données Mongo que nous avons choisie pour la production. Nous pouvons juste utiliser un fake, c’est-à-dire une implémentation naïve, simpliste.&lt;/p&gt;

&lt;h2 id=&quot;evenementiel&quot;&gt;Evenementiel&lt;/h2&gt;

&lt;p&gt;Une autre grande force de ce projet est que nous avons d’emblée pris en compte la nature événementielle d’une application. Dans un logiciel, il se passe des choses.&lt;/p&gt;

&lt;p&gt;Il est plus important de capturer des évènements que d’enregistrer l’état des objets.&lt;/p&gt;

&lt;p&gt;Malheureusement, trop d’applications sont développées en mode CRUD (Create Read Update Delete), aidées (mais pas dans le bon sens) par les frameworks de mapping ORM. Ce mode de développement rend compliqué toute migration fonctionnelle, car justement il est difficile de placer des règles métiers quand on pense que tout se limite à des opérations d’ajout/modification/suppression/lecture en base de données.&lt;/p&gt;

&lt;p&gt;En pensant événements, on est au contraire ouvert à tout ce qui peut se passer comme vérifications, contraintes, évolution du métier. On est bien plus proche des actions des utilisateurs.&lt;/p&gt;

&lt;p&gt;On peut créer des programmes plus aptes à répondre au besoin métier, et moins coincé dans une solution technique.&lt;/p&gt;

&lt;p&gt;En pratique, nos agrégats métiers émettent des événements, en réaction à des commandes, après avoir opéré les vérifications métier qui s’imposent. Nous avons mis en place un mécanisme de remontée automatique des événements (event bubbling) depuis les entités filles qui composent un agrégat global (grâce à ReactiveX et ses &lt;a href=&quot;https://reactivex.io/documentation/observable.html&quot;&gt;Observables&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&quot;partage&quot;&gt;Partage&lt;/h2&gt;

&lt;p&gt;Cela a été une discussion intéressante (parmi tant d’autres) : Comment s’y prendre pour se partager le travail et le partager avec les autres ? Bien sûr il y a l’usage de l’attirail Jira, Git, Jenkins… Mais ce qui importe c’est surtout la façon dont on s’en sert.&lt;/p&gt;

&lt;p&gt;Nous avons opté pour des &lt;a href=&quot;https://adr.github.io/&quot;&gt;ADR&lt;/a&gt; dans les points clé de notre repository, afin de garder trace de nos discussions et de remettre en contexte les choix tactiques opérés dans le code.&lt;/p&gt;

&lt;p&gt;Nous avons aussi mis l’accent sur le pair programming. Mais nous avions quand même voulu garder les &lt;a href=&quot;https://trunkbaseddevelopment.com/continuous-review/&quot;&gt;Code Reviews&lt;/a&gt;, pour prendre de la hauteur sur le code produit (essentiellement par Damien Boué et moi même). Je suis plus partisan du &lt;a href=&quot;https://www.freecodecamp.org/news/why-you-should-not-use-feature-branches-a86950126124/&quot;&gt;Trunk Based Development&lt;/a&gt;, mais en adoptant des tests plus longs à exécuter comme le Mutation Testing, il était intéressant d’isoler tout nouveau code dans une branche dédiée afin de voir s’exécuter correctement  toute la lignée de tests, sans compromettre la branche principale (on aurait pu faire du &lt;a href=&quot;https://blog.zenika.com/2018/12/03/tdd-est-mort-longue-vie-tcr/&quot;&gt;TCR&lt;/a&gt; mais c’est un peu violent).&lt;/p&gt;

&lt;p&gt;Nous avons plutôt opté pour des &lt;a href=&quot;https://trunkbaseddevelopment.com/short-lived-feature-branches/&quot;&gt;Short Lived Branch&lt;/a&gt; avec des règles du jeu : pas plus de 2 branches différentes en simultané et ne portant pas sur les mêmes “zones” du code.&lt;/p&gt;

&lt;p&gt;Au bout d’un moment, nous avions assez d’abstractions (&lt;a href=&quot;https://trunkbaseddevelopment.com/branch-by-abstraction/&quot;&gt;branching by abstraction&lt;/a&gt;) pour éviter des “rebase” douloureux.&lt;/p&gt;

&lt;p&gt;Bien sûr, quand nous avions à faire des refactoring qui touchaient plusieurs endroits du code, il fallait d’abord solder toutes les branches en cours, avant de s’attaquer à des modifications qui auraient eu trop d’impacts sur l’architecture ou les interfaces fondatrices.&lt;/p&gt;

&lt;p&gt;Pour éviter que les refactoring ne durent trop longtemps et ne conduisent à des réconciliations de code houleuses, j’ai recommandé d’adopter la méthode &lt;a href=&quot;https://blog.engineering.publicissapient.fr/2020/03/20/domptez-vos-refactoring-avec-la-mikado-method/&quot;&gt;Mikado&lt;/a&gt;, afin, une fois de plus, de progresser par petits pas, de merger très très souvent, de ne pas se lancer dans des travaux d’Hercule, et de se rendre compte des problèmes au plus tôt.&lt;/p&gt;

&lt;p&gt;Le refactoring devient également plus aisé en adoptant la méthode “&lt;a href=&quot;https://martinfowler.com/bliki/ParallelChange.html&quot;&gt;parallel change&lt;/a&gt;” ou “&lt;a href=&quot;https://medium.com/dan-the-dev/refactoring-parallel-change-trunk-based-development-97f38bea86ae&quot;&gt;expand and contract&lt;/a&gt;” : on ne casse pas l’existant; on implémente dans une nouvelle méthode ce qui doit être refactoré, et petit à petit on transite vers le nouveau code, avant d’effacer l’ancien quand il n’est plus utilisé nulle part.&lt;/p&gt;

&lt;p&gt;Encore une fois, l’architecture hexagonale, avec son découplage maximum, nous a permis de minimiser la casse.&lt;/p&gt;

&lt;p&gt;Je suis très content d’avoir travaillé comme cela, car les revues de code nous ont permis de se poser la question “est ce que notre design reste cohérent” à chaque étape de la construction du logiciel.&lt;/p&gt;

&lt;h2 id=&quot;agilité&quot;&gt;Agilité&lt;/h2&gt;

&lt;p&gt;Il était important d’avoir du feedback rapide même sur un produit qui n’est pas encore mis en exploitation. Nous avons opté pour un travail en flux type Kanban, avec des jalons variables qui étaient matérialisés par des Minor Releases, selon nos désidérata et contraintes.&lt;/p&gt;

&lt;p&gt;Nous avons pu compter sur une Intégration Continue (CI/CD) super efficace grâce au soutien de l’équipe DevOps en place.&lt;/p&gt;

&lt;h2 id=&quot;résultat&quot;&gt;Résultat&lt;/h2&gt;

&lt;p&gt;Le projet n’est pas encore terminé, et vous n’en verrez pas une démonstration graphique, car ce n’est qu’un composant au milieu de tant d’autres. Mais comme il va devenir un maillon fort de l’édifice logiciel de Primobox, c’est la fiabilité, la rapidité et la performance de produits qui vont s’en trouver renforcées. Ainsi que la maîtrise technique des équipes R&amp;amp;D.&lt;/p&gt;

&lt;h2 id=&quot;exemplaire&quot;&gt;Exemplaire&lt;/h2&gt;

&lt;p&gt;Ce qui est d’emblée visible ce sont les métriques d’un code de qualité, tel que peut nous les montrer Sonarqube. Et pour moi c’est une grande fierté d’avoir contribué à ce projet.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://dev-to-uploads.s3.amazonaws.com/uploads/articles/k30y78firzt2xl93svso.png&quot; alt=&quot;Image description&quot; /&gt;&lt;/p&gt;

&lt;!-- Footnotes themselves at the bottom. --&gt;
&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;

&lt;p&gt;Discret au sens mathématique du terme : qui est clairement délimité, séparé, isolé.&lt;/p&gt;
&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;

      &lt;p&gt;&lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;
</description>
        <pubDate>Wed, 02 Feb 2022 00:00:00 -0600</pubDate>
        <link>http://0.0.0.0:4000/le-messager/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/le-messager/</guid>
        
        
        <category>Domain Driven Design</category>
        
        <category>Architecture</category>
        
        <category>Retour d'expérience</category>
        
      </item>
    
      <item>
        <title>L'Outside-in Diamond TDD, ou l'art de mieux tester</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;Image d’illustration : Copyright 42skillz / Thomas PIERRAIN&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;le-besoin&quot;&gt;Le besoin&lt;/h2&gt;

&lt;p&gt;Développer de bons tests unitaires n’est pas une tâche aisée. Même les développeurs les plus expérimentés peuvent tomber dans les pièges “classiques” de la pratique du développement des tests automatisés.&lt;/p&gt;

&lt;p&gt;Les plus courants sont :&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Les tests fragiles&lt;/strong&gt; : ce que l’on teste dans ceux-ci est souvent l’implémentation, dû à l’utilisation excessive de mocks. Lors d’un refactoring, ils devront être mis à jour systématiquement et ce sera coûteux.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Les tests “inutiles”&lt;/strong&gt; : ce sont des tests qui couvrent du code trivial, et qui n’apportent pas de plus-value au projet. Ce sont des tests qui ne sont pas orientés métier. Par exemple : un test qui va tester une classe de mapping.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Les tests trop complexes&lt;/strong&gt; : ceux-ci sont souvent des tests d’intégration qui nécessitent beaucoup de plomberie (liée aux prérequis) que l’on ne voit pas. De ce fait, ils deviennent rapidement très difficiles à maintenir. Ils sont souvent très lents à exécuter, difficiles à comprendre et portent sur du code complexe avec de nombreuses lignes de code.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Mais alors, comment peut-on réaliser des tests plus robustes ? Pour cela, laissez-moi vous présenter l’&lt;strong&gt;Outside-in Diamond TDD&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;quest-ce-que-loutside-in-diamond-tdd-&quot;&gt;Qu’est ce que l’Outside-in Diamond TDD ?&lt;/h2&gt;

&lt;p&gt;L’Outside-in Diamond TDD est une technique d’approche des tests unitaires mise au point par &lt;a href=&quot;http://tpierrain.blogspot.com/&quot;&gt;&lt;strong&gt;Thomas Pierrain&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;L’idée de base est née d’une constatation : la notion de tests unitaires est mal comprise par la majorité des développeurs. En effet, ceux-ci pensent qu’un test unitaire est un bout de code qui va tester un petit composant en isolation des autres. Or, comme le fait si bien remarquer Thomas Pierrain, la définition de &lt;a href=&quot;https://fr.wikipedia.org/wiki/Kent_Beck&quot;&gt;&lt;strong&gt;Kent Beck&lt;/strong&gt;&lt;/a&gt; est beaucoup plus juste :&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Tests that “runs in isolation” from other tests (des tests qui s’exécutent en isolation des autres tests)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Un bon test unitaire s’isole donc lui-même des autres tests, il n’isole pas le composant qu’il teste des autres composants. Cela veut dire que l’on peut faire des tests unitaires qui ne testent pas qu’une classe. Ce n’est pas tout : un bon test unitaire s’isole avant tout des dépendances externes (base de données, disque, API externe…).&lt;/p&gt;

&lt;p&gt;De plus, Thomas Pierrain a constaté que la &lt;a href=&quot;https://martinfowler.com/bliki/TestPyramid.html&quot;&gt;&lt;strong&gt;pyramide des tests&lt;/strong&gt;&lt;/a&gt; est souvent utilisée de manière dogmatique sans que les développeurs ne se posent la question de ce qui est pertinent à tester.&lt;/p&gt;

&lt;p&gt;Pendant longtemps, il a cherché à lutter pour faire oublier ces fausses idées, sans succès. J’aime bien sa référence à la loi d’&lt;a href=&quot;https://fr.wikipedia.org/wiki/Loi_de_Brandolini&quot;&gt;&lt;strong&gt;Alberto Brandolini&lt;/strong&gt;&lt;/a&gt; à propos de ce sujet :&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“The amount of energy needed to refute bullshit is an order of magnitude larger than to produce it”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Donc plutôt que de lutter inutilement pour faire admettre ces idées, Thomas Pierrain est parti sur l’idée de promouvoir les &lt;a href=&quot;https://fr.wikipedia.org/wiki/Test_d%27acceptation&quot;&gt;&lt;strong&gt;tests d’acceptation&lt;/strong&gt;&lt;/a&gt;. En effet, ceux-ci sont plus faciles à faire accepter pour voir le système à tester comme une boîte noire. Les développeurs auront alors plutôt tendance à tester en termes de contrat métier, ce qui est plus sain pour la maintenabilité des projets.&lt;/p&gt;

&lt;h4 id=&quot;outside-in&quot;&gt;Outside-in&lt;/h4&gt;

&lt;p&gt;La notion d’&lt;strong&gt;Outside-in TDD&lt;/strong&gt; est assez simple à comprendre : on teste de l’extérieur en allant vers l’intérieur.&lt;/p&gt;

&lt;p&gt;On commence donc par écrire des &lt;strong&gt;tests d’acceptation&lt;/strong&gt; “gros grains” qui sont orientés métier et testent le système en boîte noire. Pendant la phase red de TDD portant sur ces tests gros grains, on peut être amené à réaliser des boucles TDD plus petites sur l’intérieur du système, typiquement sur le modèle du domaine. A la fin, une fois toutes ces petites boucles réalisées, la boucle principale “gros grain” deviendra alors passante.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;L’énorme avantage de cette approche&lt;/strong&gt; par rapport à l’inside out (beaucoup plus répandu) est que l’on ne crée pas de test ou de code de production qui ne correspond pas à un besoin métier. Cela n’est pas sans rappeler le principe &lt;strong&gt;YAGNI&lt;/strong&gt; (You Ain’t Gonna Need It). Pas de superflu !&lt;/p&gt;

&lt;h4 id=&quot;diamond&quot;&gt;Diamond&lt;/h4&gt;

&lt;p&gt;La notion de &lt;strong&gt;Diamond&lt;/strong&gt; vient du fait que les tests réalisés changent complètement la pyramide de test telle que nous la connaissons.&lt;/p&gt;

&lt;p&gt;Le diamant est fait pour symboliser l’importance et la prépondérance de ces tests d’acceptation par rapport aux autres types de tests (cf. image en haut de l’article) : tests unitaires, tests d’intégration, tests end-to-end.&lt;/p&gt;

&lt;p&gt;Ce style de TDD nous oriente donc à écrire plus de tests haut niveau et moins de tests dans le détail.&lt;/p&gt;

&lt;h2 id=&quot;pourquoi-loutside-in-diamond-tdd-est-si-intéressant-&quot;&gt;Pourquoi l’Outside-in Diamond TDD est si intéressant ?&lt;/h2&gt;

&lt;p&gt;Cela fait quelques années maintenant que j’utilise l’&lt;a href=&quot;https://fr.wikipedia.org/wiki/Architecture_hexagonale_(logiciel)&quot;&gt;&lt;strong&gt;architecture hexagonale&lt;/strong&gt;&lt;/a&gt; dans mes projets en production. J’ai toujours privilégié les tests unitaires au niveau de mon modèle de domaine, en les construisant à partir des différents cas manipulés par mes services applicatifs.&lt;/p&gt;

&lt;p&gt;Le schéma ci-dessous représente &lt;strong&gt;en vert la partie couverte&lt;/strong&gt; par les tests unitaires tels que je les réalisais :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/outside-in-diamond-tdd/old-hexagon-tests.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cela pose un problème majeur&lt;/strong&gt;. Il y a tout une partie de code qui se retrouve non testée : les adaptateurs de gauche (API REST par exemple) et les adaptateurs de droite (base de données par exemple). Ces parties sont matérialisées en jaune sur le schéma. Bien sûr, ils étaient couverts par les tests d’intégration, mais les tests d’intégration sont &lt;u&gt;lents&lt;/u&gt;.&lt;/p&gt;

&lt;p&gt;Thomas Pierrain nous fait le retour d’expérience suivant : la plupart des bugs subtils proviennent de ce code non testé, présent dans les adaptateurs. Il préconise donc de tester &lt;strong&gt;&lt;u&gt;tout l'hexagone&lt;/u&gt;&lt;/strong&gt;, en partant des adaptateurs de gauche, ainsi qu’en incluant les adaptateurs de droite (en mockant ou fakant uniquement les I/O, que ce soit de la base de données, du fichier ou du réseau).&lt;/p&gt;

&lt;p&gt;C’est là tout l’intérêt de ce pattern de tests : on a des tests à la fois &lt;strong&gt;rapides&lt;/strong&gt; et qui couvrent &lt;strong&gt;largement&lt;/strong&gt; notre base de code.&lt;/p&gt;

&lt;p&gt;On a alors un code couvert comme cela :&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;../assets/images/outside-in-diamond-tdd/new-hexagon-tests.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Voyons maintenant un exemple de code pour ces tests (gestion de panier sur un site de e-commerce) :&lt;/p&gt;

&lt;noscript&gt;&lt;pre&gt;400: Invalid request&lt;/pre&gt;&lt;/noscript&gt;
&lt;script src=&quot;https://gist.github.com/83f89ba6a992b4b7e852f440c307710c.js&quot;&gt; &lt;/script&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Finalement, qu’est ce que c’est qu’un &lt;em&gt;“bon”&lt;/em&gt; test unitaire ? Il existe autant de définitions d’un bon test qu’il existe de développeurs.&lt;/p&gt;

&lt;p&gt;Pour moi, un bon test unitaire est un test qui va &lt;strong&gt;tester un contrat métier&lt;/strong&gt;, sans se préoccuper de l’implémentation. De cette manière, il pourra survivre à tous les refactorings.&lt;/p&gt;

&lt;p&gt;Mais ce n’est pas tout. Un bon test unitaire doit être &lt;strong&gt;parlant&lt;/strong&gt;. Il doit être &lt;strong&gt;concis&lt;/strong&gt;. Malheureusement, le code des tests unitaires est souvent considéré comme moins important que le code de production et c’est une erreur. Il faut qu’il soit traité avec la plus grande attention. Je vais même aller plus loin : si un test est bien écrit, il sera la documentation de votre use case que vous n’écrirez jamais.&lt;/p&gt;

&lt;p&gt;Personnellement, j’aime bien l’approche proposée par &lt;a href=&quot;https://techleadjournal.dev/episodes/58/&quot;&gt;&lt;strong&gt;Vladimir Khorikov&lt;/strong&gt;&lt;/a&gt; pour définir la valeur d’un test. Pour lui, les 4 piliers fondamentaux d’un bon test sont :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;qu’il doit permettre d’intercepter une régression&lt;/li&gt;
  &lt;li&gt;qu’il doit résister aux refactorings (grâce au fait qu’il ne soit pas lié à l’implémentation du système testé)&lt;/li&gt;
  &lt;li&gt;qu’il doit fournir un feedback très rapide&lt;/li&gt;
  &lt;li&gt;qu’il doit avoir un coût de maintenance faible&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Je trouve que les tests réalisés en Outside-in Diamond TDD remplissent très bien ces fonctions :&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ils interceptent bien les régressions car ce sont des tests d’acceptation orientés métier qui testent du comportement. Si celui-ci change, alors on le sait immédiatement.&lt;/li&gt;
  &lt;li&gt;ils résistent au refactoring car on teste en boîte noire l’hexagone complet en partant des adaptateurs de gauche&lt;/li&gt;
  &lt;li&gt;ils sont rapides, car on utilise le moins de frameworks possible et on mock les I/O (BDD, système de fichiers, réseau…)&lt;/li&gt;
  &lt;li&gt;ils ont un coût de maintenance faible de par leur nature “métier”&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Un autre avantage indéniable que je trouve à ce pattern de TDD : il permet d’écrire &lt;strong&gt;moins de tests&lt;/strong&gt; et &lt;strong&gt;mieux&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Chez &lt;strong&gt;Primobox&lt;/strong&gt;, nous mettons en place ce pattern de tests afin de pérenniser nos projets sur le long terme.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Sources :&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://tpierrain.blogspot.com/2021/03/outside-in-diamond-tdd-1-style-made.html&quot;&gt;Outside-in Diamond 🔷 TDD #1 - a style made from (&amp;amp; for) ordinary people&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://tpierrain.blogspot.com/2021/03/outside-in-diamond-tdd-2-anatomy-of.html&quot;&gt;Outside-in Diamond 🔷 TDD #2 (anatomy of a style)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://techleadjournal.dev/episodes/58/&quot;&gt;Tech Lead Journal #58 - Principles for Writing Valuable Unit Tests - Vladimir Khorikov&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 15 Jan 2022 00:00:00 -0600</pubDate>
        <link>http://0.0.0.0:4000/outside-in-tdd-diamond/</link>
        <guid isPermaLink="true">http://0.0.0.0:4000/outside-in-tdd-diamond/</guid>
        
        
        <category>TDD</category>
        
        <category>Architecture</category>
        
      </item>
    
  </channel>
</rss>
